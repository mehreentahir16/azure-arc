{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1641746339465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load workspace configuration from the config.json file in the current folder.\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641746339749
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create script folder \n",
        "import os \n",
        "script_folder = os.path.join(os.getcwd(), 'script') \n",
        "os.makedirs(script_folder, exist_ok=True) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641746340057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile script/train.py\n",
        "\n",
        "import os\n",
        "import time\n",
        "import azureml\n",
        "import argparse\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from keras import utils, losses\n",
        "from keras.models import Sequential\n",
        "from azureml.core import Workspace, Run\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]= \"2\"\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "\n",
        "#Fashion MNIST Dataset CNN model development: https://github.com/zalandoresearch/fashion-mnist\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
        "args = parser.parse_args()\n",
        "\n",
        "# declare variables for model training\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "img_rows,img_cols = 28,28\n",
        "\n",
        "#load training and testing data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, sep = '\\n')\n",
        "\n",
        "# Define the labels\n",
        "fashion_mnist_labels = [\"Top\",          \n",
        "                        \"Trouser\",      \n",
        "                        \"Jumper\",        \n",
        "                        \"Dress\",         \n",
        "                        \"Coat\",         \n",
        "                        \"Sandal\",       \n",
        "                        \"Shirt\",        \n",
        "                        \"Trainer\",       \n",
        "                        \"Bag\",          \n",
        "                        \"Ankle boot\"]   \n",
        "\n",
        "#data pre-processing\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test,  num_classes)\n",
        "\n",
        "#formatting issues for depth of image (greyscale = 1) with different kernels (tensorflow, cntk, etc)\n",
        "if K.image_data_format()== 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0],1,img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
        "    x_test = x_test.reshape(x_test.shape[0],img_rows, img_cols,1)\n",
        "    input_shape = (img_rows, img_cols,1)\n",
        "    \n",
        "    \n",
        "# model for image classification\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), padding = 'same', activation = 'relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding = 'same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# start an Azure ML run\n",
        "run = Run.get_context()\n",
        "\n",
        "print('Train a deep learning model')\n",
        "model.compile(loss=losses.categorical_crossentropy, optimizer=\"Adam\", metrics=['accuracy'])\n",
        "hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# evaluate the model performance on test data\n",
        "print('Predict the test set')\n",
        "result = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test Loss: ', result[0])\n",
        "print('Test Accuracy: ', result[1])\n",
        "\n",
        "# calculate accuracy on the prediction\n",
        "print('Accuracy is', result[1])\n",
        "run.log('accuracy', np.float(result[1]))\n",
        "\n",
        "os.makedirs('outputs/model', exist_ok=True) \n",
        "\n",
        "# save trained model \n",
        "model.save('outputs/model/model.h5') \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get attached Arc-enabled kubernetes compute\n",
        "arc_compute = ws.compute_targets[\"arc-ml-demo\"] "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641746340714
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core import ScriptRunConfig\n",
        "\n",
        "# Register environment to re-use later\n",
        "env = Environment('test')\n",
        "conda_dep = packages = CondaDependencies.create(conda_packages=['pip', 'tensorflow', 'keras', 'scikit-learn', 'h5py'],\n",
        "                                    pip_packages=['azureml-defaults'])\n",
        "env.python.conda_dependencies = conda_dep\n",
        "env.register(workspace = ws)\n",
        "\n",
        "# reference the data\n",
        "datastore = ws.get_default_datastore()\n",
        "data_ref = datastore.path('./data').as_mount()\n",
        "\n",
        "src = ScriptRunConfig(source_directory=script_folder,\n",
        "                      script='train.py',\n",
        "                      arguments=['--data-folder', str(data_ref)],\n",
        "                      compute_target=arc_compute,\n",
        "                      environment=env)\n",
        "                      \n",
        "# Run the experiment\n",
        "src.run_config.data_references = {data_ref.data_reference_name: data_ref.to_config()}\n",
        "run = Experiment(workspace=ws, name='fashion-mnist').submit(src)\n",
        "run.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641747343593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_metrics())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641747842562
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get files in experiment record\n",
        "print(run.get_file_names())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641747846050
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.download_file(name=\"./outputs/model/model.h5\", output_file_path=\"./outputs/model/model.h5\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641747853623
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# register model \n",
        "model = run.register_model(model_name='fashion-mnist', model_path='./outputs/model/model.h5')\n",
        "print(model.name, model.id, model.version, sep = '\\t')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1641747881050
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}